{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 50 оттенков градиентного спуска \n",
    "\n",
    "В этом задании вам предстоит реализовать линейный классификатор и натренировать его, используя различные модификации градинетного спуска. Тетрадка позаимствована с [шадовского курса по нейронкам.](https://github.com/yandexdataschool/Practical_DL/blob/master/week01_backprop/adapdive_sgd/adaptive_sgd.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Генерация выборки\n",
    "\n",
    "Для наших целей будем использовать искуственно сгенерированные данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, preprocessing\n",
    "\n",
    "# keep random_state=42 for deterministic results\n",
    "(X, y) = datasets.make_circles(n_samples=1024, shuffle=True, noise=0.2, factor=0.4, random_state=42)\n",
    "ind = np.logical_or(y == 1, X[:, 1] > X[:, 0] - 0.5)\n",
    "X = X[ind, :]\n",
    "m = np.array([[1, 1], [-2, 1]])\n",
    "X = preprocessing.scale(X)\n",
    "y = y[ind]\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Paired, s=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1] Варка фичей\n",
    "\n",
    "Как вы можете заметить, данные не являются линейно разделимыми. Нам придётся добавить в обучающую выборку новые фичи либо использовать нелинейные модели. Предположим, что разделяющая поверхность имеет вид окружности. Добавьте в матрицу признаков дополнительные колонки $x_1^2$, $x_2^2$ и $x_1 \\cdot x_2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand(X):\n",
    "    \"\"\"\n",
    "    Добавляет квадратичные фичи. \n",
    "    Для каждой строки матрицы находит строку \n",
    "    [feature0, feature1, feature0^2, feature1^2, feature0*feature1, 1]\n",
    "    \n",
    "    :param X: матрица фичей, shape [n_samples,2]\n",
    "    :returns: расширенная матрица фичей, shape [n_samples,6]\n",
    "    \"\"\"\n",
    "\n",
    "    # ваш код здесь\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [3] Логистическая регрессия \n",
    "\n",
    "Для классификации будем использовать логистическую регрессию. \n",
    "\n",
    "$$ a(x; w) = \\langle w, x \\rangle $$\n",
    "$$ P( y=1 \\; \\big| \\; x, \\, w) = \\dfrac{1}{1 + \\exp(- \\langle w, x \\rangle)} = \\sigma(\\langle w, x \\rangle)$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability(X, w):\n",
    "    \"\"\"\n",
    "    Принимает на вход матрицу фичей и вектор весов\n",
    "    Возвращает предсказание вероятность того, что y = 1 при фиксированных x, P(y=1|x)\n",
    "    \n",
    "    :param X: расширенная матрица фичей [n_samples,6] (expanded)\n",
    "    :param w: вектор весов [6]\n",
    "    :returns: вектор вероятностей\n",
    "    \"\"\"\n",
    "\n",
    "    # ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для логистической регрессии оптимальный параметр находится минимизацией кросс-энтропии: \n",
    "\n",
    "$$ L(w) =  - {1 \\over \\ell} \\sum_{i=1}^\\ell \\left[ {y_i \\cdot log P(y_i = 1 \\, | \\, x_i,w) + (1-y_i) \\cdot log (1-P(y_i = 1 \\, | \\, x_i,w))}\\right] $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(X, y, w):\n",
    "    \"\"\"\n",
    "    Принимает на вход матрицу весов, вектор ответов и вектор весов.\n",
    "    Выдаёт на выход значение функции потерь, расчитанное по формуле выше.\n",
    "    \"\"\"\n",
    "\n",
    "    # ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы будем обучать модель методом градиентного спуска. Для этого нам придётся вычислить градиент функции потерь, представленной выше. Возьмите листочек, ручку и в бой! \n",
    "\n",
    "$$ \\nabla_w L = ...$$\n",
    "\n",
    "Тут обойдёмся даже без матричного дифириенцирования. А вот в следущий раз его не миновать..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_grad(X, y, w):\n",
    "    \"\"\"\n",
    "    Нахоит значение градиента.\n",
    "    \"\"\"\n",
    "\n",
    "    # ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция ниже предназначена для визуализации процесса обучения. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "\n",
    "h = 0.01\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "def visualize(X, y, w, history):\n",
    "    \"\"\"С помощью магии matplolib выдаёт красоты результатов классификации\"\"\"\n",
    "    Z = probability(expand(np.c_[xx.ravel(), yy.ravel()]), w)\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.contourf(xx, yy, Z, alpha=0.8)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Paired)\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history)\n",
    "    plt.grid()\n",
    "    ymin, ymax = plt.ylim()\n",
    "    plt.ylim(0, ymax)\n",
    "    display.clear_output(wait=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# убедитесь, что у вас она работает, запустив код ниже \n",
    "# (он отработает если вы верно реализовали expend и probability)\n",
    "dummy_weights = np.linspace(-1, 1, 6)\n",
    "visualize(X, y, dummy_weights, [0.5, 0.5, 0.25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение\n",
    "\n",
    "Пришло время обучить нашу модель. Для этого вам придётся дописать кусочки функций ниже. Обязательно попробуйте поменять гиперпараметры (размер батча и скорость обучения) и посмотреть как будет изменяться анимация. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2] Mini-batch SGD\n",
    "\n",
    "Берём несколько рандомных наблюдений и ищем градиент по ним! \n",
    "\n",
    "$$ w_t = w_{t-1} - \\eta \\dfrac{1}{m} \\sum_{j=1}^m \\nabla_w L(w_t, x_{i_j}, y_{i_j}) $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "w = np.array([0, 0, 0, 0, 0, 1])\n",
    "\n",
    "eta= 0.1 \n",
    "\n",
    "n_iter = 100\n",
    "batch_size = 4\n",
    "loss = np.zeros(n_iter)\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "for i in range(n_iter):\n",
    "    \n",
    "    # Ваш код здесь \n",
    "\n",
    "visualize(X, y, w, loss)\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2] Momentum SGD\n",
    "\n",
    "Momentum это метод, который помогает стохастическому градиентному спуску сохранять направление движения. Это осуществляется за счёт добавления в выражение дополнительного слагаемого: накопленного за предыдущие шаги градиента с весом $\\alpha$. \n",
    "<br>\n",
    "<br>\n",
    "\n",
    "$$ \\nu_t = \\alpha \\nu_{t-1} + \\eta\\dfrac{1}{m} \\sum_{j=1}^m \\nabla_w L(w_t, x_{i_j}, y_{i_j}) $$\n",
    "$$ w_t = w_{t-1} - \\nu_t$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "w = np.array([0, 0, 0, 0, 0, 1])\n",
    "\n",
    "eta = 0.05 \n",
    "alpha = 0.9 \n",
    "nu = np.zeros_like(w)\n",
    "\n",
    "n_iter = 100\n",
    "batch_size = 4\n",
    "loss = np.zeros(n_iter)\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "for i in range(n_iter):\n",
    "    \n",
    "    # Ваш код здесь \n",
    "\n",
    "visualize(X, y, w, loss)\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2] RMSprop\n",
    "\n",
    "В этом блоке реализуем RMSprop. Эта вариация градиентного спуска позволяет изменять скорость обучения индивидуально для каждого параметра. \n",
    "\n",
    "$$ G_t^j = \\alpha G_{t-1}^j + (1 - \\alpha) g_{tj}^2 $$\n",
    "$$ w_t^j = w_{t-1}^j - \\dfrac{\\eta}{\\sqrt{G_t^j + \\varepsilon}} g_{tj} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "w = np.array([0, 0, 0, 0, 0, 1.])\n",
    "\n",
    "eta = 0.1 \n",
    "alpha = 0.9 \n",
    "g2 = np.zeros_like(w)\n",
    "eps = 1e-8\n",
    "\n",
    "n_iter = 100\n",
    "batch_size = 4\n",
    "loss = np.zeros(n_iter)\n",
    "plt.figure(figsize=(12,5))\n",
    "for i in range(n_iter):\n",
    "\n",
    "    # Ваш код здесь \n",
    "\n",
    "visualize(X, y, w, loss)\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как траектории обучения различных вариаций градиентного спуска различаются между собой? Ожидаемо ли это? Почему? Что нужно сделать, чтобы реализовать Adam? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2] За каждую адекватную вариацию\n",
    "\n",
    "Если понравилось реализовывать свои градиентные спуски и ты находишься от них под глубоким впечатлением, я могу накинуть два дополнительных балла за реализацию каждой новой адекватной вариации. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
